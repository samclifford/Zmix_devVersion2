ls()
window
ls()
getwd()
load('~/Google Drive/Work/CSIRO_P1/PP_Y4.RDATA')
ls()
Y4_AD_pp[[1]]
Y4_AD_pp[[2]]
load('~/Google Drive/Work/CSIRO_P1/PP_Y37.RDATA')
ls()
names(Y37_AD_pp)
Y4_AD_pp[[3]]
Y4_AD_pp[[4]]
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_zmixTEST.RDATA')
ls()
?write.csv
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_testingVentrolateral.Prefrontal.RDATA')
ls()
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLAnterior.Cingulate.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLInsula.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLLateral.Occipital.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLOrbito.Frontal.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLPosterior.Cingulate.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLPrimary.Visual.Cortex.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLSensoryMotor.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLSuperior.Parietal.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLSupramarginal.Gyrus.RDATA')#
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLVentrolateral.Prefrontal.RDATA')
33/10
33/3
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLOrbito.Frontal.RDATA')#
    .thisModel<-which.max(Final_Result[[2]]$Probability)#
    .thisK0<-Final_Result[[2]]$K0[.thisModel]
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLOrbito.Frontal.RDATA')
ls()
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLOrbito.Frontal.RDATA')
load('~/Google Drive/Work/CSIRO_P1/Code/Combine_Result.K02.midpoints.RDATA')
ls()
Combine_Result.K02.midpoints
Combine_Result.K02.midpoints[order(Combine_Result.K02.midpoints$MidPoint)]
Combine_Result.K02.midpoints[order(Combine_Result.K02.midpoints$MidPoint),]
Alz_TopModel<-Alz_TopModel_REV
# compute prop k=1 vs others by region
Alz_TopModel<-cbind(Alz_TopModel,"k_hilo"=Alz_TopModel$k )
load('~/Google Drive/Work/CSIRO_P1/Results_Run_Singles/Zmix_ZMIX_ALLFusiform.RDATA')
ls()
Final_Result[[1]]
Final_Result[[2]]
ls()
load('~/Google Drive/Work/CSIRO_P1/Code/morning_nov2ish.RDATA')
all.zmixMVN<-Zmix_multi_tempered(BigY[,c(4:35,37)], iter=50, k=3, sim=FALSE, EndSize=30, alphas= c(1, 0.5, 1/2^(c(10, 15, 30))))  #FIX ME
all.zmixMVN<-Zmix_multi_tempered(BigY[,c(4:35,37)], iter=300, k=5, sim=FALSE, EndSize=200, alphas= c(1, 0.5, 1/2^(c(2,10, 15, 30))))  #FIX ME
all.pc.zmixMVN.pp<-PostProc_mvn(all.pc.zmixMVN, Y.pc, Propmin=0.01, isSim=FALSE, simlabel="SUVR_First4PCs")
all.pc.zmixMVN.pp<-PostProc_mvn(all.pc.zmixMVN, as.data.frame(Y.pc), Propmin=0.01, isSim=FALSE, simlabel="SUVR_First4PCs")
#' PostProcessing function univ#
#'#
#' This function draws samples from a Wishart dist#
#' @param v and s#
#' @keywords Wishart#
#' @export#
#' @examples#
#' #nope#
PostProc_mvn<-function( Grun,  mydata,Propmin=0.05, isSim=TRUE, simlabel="sim", savelabel="PPplot"){#
            require(wq)#
        ifelse(isSim==TRUE, Y<-mydata$Y,  Y<-mydata)#
#
        n<-dim(Y)[1] #
        r<-dim(Y)[2]#
        k<-dim(Grun$P)[2]   #
        ## 1. split by K0#
        K0<-as.numeric(names(table(Grun$SteadyScore)))#
        # SAVE table of tests, parameter estimates and clustering (Z's)#
         p_vals<-data.frame("K0"=K0, "PropIters"=as.numeric(table(Grun$SteadyScore))/dim(Grun$P)[1],#
             "RAND"=NA, "MAE"=NA, "MSE"=NA,"Pmin"=NA, "Pmax"=NA, "Concordance"=NA, "MAPE"=NA, "MSPE"=NA)#
        K0estimates<-vector("list", length(K0))#
        GrunK0us_FIN<-vector("list", length(K0))#
#
    #for each K0:#
        for ( .K0 in 1:length(K0)){#
        GrunK0<-Grun#
        # split data by K0#
        .iterK0<-c(1:dim(Grun$P)[1])[Grun$SteadyScore==K0[.K0]]#
        GrunK0$Mu<-Grun$Mu[ Grun$Mu$Iteration %in% (min(Grun$Mu$Iteration)+.iterK0-1),]#
        GrunK0$Cov<-Grun$Cov[ Grun$Mu$Iteration %in% (min(Grun$Cov$Iteration)+.iterK0-1),]#
#
        GrunK0$P<-  Grun$P[.iterK0,]#
        GrunK0$Loglike<-    Grun$Loglike[.iterK0]#
        GrunK0$Zs<- Grun$Zs[.iterK0,]#
        GrunK0$SteadyScore<-    Grun$SteadyScore[.iterK0]#
#
        ## 2. unswitch#
        GrunK0us<-QuickSwitchMVN(GrunK0,Propmin )#
        GrunK0us_FIN[[.K0]]<-GrunK0us#
        maxZ<-function (x)  as.numeric(names(which.max(table( x ))))#
        Zhat<- factor( apply(t(GrunK0us$Zs), 1,maxZ))#
            ## 3. RAND  #
            if(isSim==TRUE){#
            #maxZ<-function (x)  as.numeric(names(which.max(table( x ))))#
            #Zhat<- factor( apply(t(GrunK0us$Zs), 2,maxZ)); #
            p_vals$RAND[.K0]<-(sum(mydata$Z==Zhat)/n) #
            } else { p_vals$RAND[.K0]<-'NA'}#
        names(GrunK0us$Pars)[1]<-'k'#
            GrunK0us$Pars$k<-as.numeric(as.character(GrunK0us$Pars$k))#
#
            # COMPUTE means of parameters#
            #.par<-melt(GrunK0us$Pars, id.vars=c("Iteration", "k"))#
        #   Zetc<-aggregate( value~variable+factor(k), mean ,data=.par)#
        # CI#
        .par<-melt(GrunK0us$Pars, id.vars=c("Iteration", "k"))#
        theta<-aggregate( value~variable+factor(k), mean ,data=.par)#
        mu<-round(aggregate( value~variable+factor(k), mean ,data=.par)[,3], 2)#
        ci<-round(aggregate( value~variable+factor(k), quantile,c(0.025, 0.975) ,data=.par)[,3],2)#
        thetaCI<-cbind( theta[,c(1,2)] , "value"=paste( mu, "(", ci[,1] , "," ,ci[,2] ,")", sep="" ))#
        K0estimates[[.K0]]<-cbind(thetaCI, "K0"=K0[.K0])#
#
# PLOTS density pars#
    GrunK0us$Pars$k<-as.factor(GrunK0us$Pars$k)#
#
plot_P<-ggplot(data=GrunK0us$Pars, aes(y=P, x=k)) + geom_boxplot(aes(fill=k), outlier.shape = NA)+#
        ggtitle( bquote( atop(italic( .(simlabel) ), atop("Weights"))))+ ylab("")+xlab("Components (k)")  +theme_bw()+  theme(legend.position = "none")#
#
plot_Mu1<-ggplot(data=GrunK0us$Pars, aes(y=Mu_1, x=k))  + geom_boxplot(aes(fill=k), outlier.shape = NA)+ggtitle(bquote(atop(italic( "Posterior summaries"), atop("Means (Dim 1)"))))+ylab("Mean (Dim 1)")+xlab("Cluster (k)") +theme_bw()+  theme(legend.position = "none")#
#
plot_Mu2<-ggplot(data=GrunK0us$Pars, aes(y=Mu_2, x=k))  + geom_boxplot(aes(fill=k), outlier.shape = NA)+#
        ggtitle(bquote(atop(italic(paste( "p(K=", .(K0[.K0]), ")=",  .(p_vals$PropIters[.K0]), sep="")), atop("Means (Dim 2)"))))+ylab("Mean (Dim 2)")+xlab("Cluster (k)") +theme_bw()+  theme(legend.position = "none")#
# plot clusters#
names(Y)<-paste("Y", 1:r, sep="_")#
Clusplot<-ggplot( cbind(Y, "Cluster"=Zhat), aes(y=Y_1, x=Y_2, shape=Cluster, colour=Cluster))+geom_point()+theme_bw()+  theme(legend.position = "none")#
Clusplot2<-ggplot( cbind(Y, "Cluster"=Zhat), aes(y=Y_1, x=Y_3, shape=Cluster, colour=Cluster))+geom_point()+theme_bw()+  theme(legend.position = "none")#
Clusplot3<-ggplot( cbind(Y, "Cluster"=Zhat), aes(y=Y_2, x=Y_3, shape=Cluster, colour=Cluster))+geom_point()+theme_bw()#
        pdf( file= paste("PPplots_", savelabel ,"K_", K0[.K0] ,".pdf", sep=""), width=10, height=5)#
        print( layout(#
        list(plot_P,    1, 1),  #
                list(plot_Mu1,  1, 2),   #
                list(plot_Mu2,  1,3),#
                list(Clusplot,  2,1),#
                list(Clusplot2, 2,2),#
                list(Clusplot3, 2,3)#
            )#
        )#
        dev.off()#
#
        }#
        Final_Pars<-do.call(rbind, K0estimates)#
        return(list( Final_Pars, p_vals, "Z"=Zhat))#
        }
all.pc.zmixMVN.tiny<-Zmix_multi_tempered(Y.pc, iter=300, k=10, sim=FALSE, EndSize=500, alphas= c(1/2^(c(20,30))))
all.pc.zmixMVN.tiny<-Zmix_multi_tempered(Y.pc, iter=500, k=10, sim=FALSE, EndSize=200,alphas= c(1/2^(c(30, 40))))
all.pc.zmixMVN.tiny<-Zmix_multi_tempered(BigY[,c(4:35,37)], iter=500, k=10, sim=FALSE, EndSize=200,alphas= c(1/2^(c(30, 40))))
all.zmixMVN.tiny<-Zmix_multi_tempered(BigY[,c(4:35,37)], iter=500, k=10, sim=FALSE, EndSize=200,alphas= c(1/2^(c(30, 40))))#
all.zmixMVN.tiny.pp<-PostProc_mvn(all.zmixMVN.tiny, as.data.frame(Y.pc), Propmin=0.01, isSim=FALSE, simlabel="SUVR_MVNall_quicktest")
Grun<-all.pc.zmixMVN.tiny  ;   mydata<- as.data.frame(Y.pc)
Clusplot<-ggplot( data.frame(Y, "Cluster"=Zhat), aes(y=Y_1, x=Y_2, shape=Cluster, colour=Cluster))+geom_point()+theme_bw()+  theme(legend.position = "none")#
Clusplot2<-ggplot( cbind(Y, "Cluster"=Zhat), aes(y=Y_1, x=Y_3, shape=Cluster, colour=Cluster))+geom_point()+theme_bw()+  theme(legend.position = "none")#
Clusplot3<-ggplot( cbind(Y, "Cluster"=Zhat), aes(y=Y_2, x=Y_3, shape=Cluster, colour=Cluster))+geom_point()+theme_bw()
print( wq::layOut(#
        list(plot_P,    1, 1),#
                list(plot_Mu1,  1, 2),#
                list(plot_Mu2,  1,3),#
                list(Clusplot,  2,1),#
                list(Clusplot2, 2,2),#
                list(Clusplot3, 2,3),#
                list(curvePlot, 3, 1:3)#
            )#
        )
print( layOut(#
        list(plot_P,    1, 1),#
                list(plot_Mu1,  1, 2),#
                list(plot_Mu2,  1,3),#
                list(Clusplot,  2,1),#
                list(Clusplot2, 2,2),#
                list(Clusplot3, 2,3)#
            )#
        )
Y.pc
setwd("/Users/van42c/Google Drive/Work/GitHub/Zmix_devVersion2/R")
ls()
getwd()
document()
library(devtools)#
library(roxygen2)#
install_github('username/mypackage')#
library(mypackage)
document()
document()
document()
document()
devtools::use_data(OfficialNames)
document()
document()
document()
document()
image(dist(BigY[,c(4:35,37)]))
image(dist(BigY[,as.matrix(c(4:35,37)])))
image(dist(BigY[,as.matrix(c(4:35,37))]))
matrix(BigY[,c(4:35,37)])
as.matrix(BigY[,c(4:35,37)])
image(dist(as.matrix(BigY[,c(4:35,37)]))
)
all.dist<-0dist(as.matrix(BigY[,c(4:35,37)]))
all.dist<-dist(as.matrix(BigY[,c(4:35,37)]))
all.dist
class(all.dist)
as.data.frame(all.dist)
as.data.frame(all.dist)
head(all.dist)
head(all.dist, 100)
plot(all.dist)
all.dist<-simil(as.matrix(BigY[,c(4:35,37)]))
library('proxy')
library("proxi")
library("proxy")
all.simil<-simil(as.matrix(BigY[,c(4:35,37)]))
plot(all.simil)
dim(all.simil)
(all.simil)image
image(all.simil)
(all.simil)head
head(all.simil)
as.matrix(all.simil)
image(as.matrix(all.simil))
dij <- dist(BigY[,c(4:35,37)])
clust <- hclust(dij, method = "average")
ord <- order(cutree(clust, k = 3))
ord
coph <- cophenetic(clust)
coph
layout(matrix(1:4, ncol = 2))#
image(as.matrix(dij)[ord, ord], main = "Original distances")#
image(as.matrix(coph)[ord, ord], main = "Cophenetic distances")#
image((as.matrix(coph) - as.matrix(dij))[ord, ord], #
      main = "Cophenetic - Original")#
plot(coph ~ dij, ylab = "Cophenetic distances", xlab = "Original distances",#
     main = "Shepard Plot")#
abline(0,1, col = "red")#
box()#
layout(1)
dij <- dist(BigY[,c(4:35,37)])#
clust <- hclust(dij, method = "average")#
ord <- order(cutree(clust, k = 5))#
coph <- cophenetic(clust)#
layout(matrix(1:4, ncol = 2))#
image(as.matrix(dij)[ord, ord], main = "Original distances")#
image(as.matrix(coph)[ord, ord], main = "Cophenetic distances")#
image((as.matrix(coph) - as.matrix(dij))[ord, ord], #
      main = "Cophenetic - Original")#
plot(coph ~ dij, ylab = "Cophenetic distances", xlab = "Original distances",#
     main = "Shepard Plot")#
abline(0,1, col = "red")#
box()#
layout(1)
dij <- dist(BigY[,c(4:35,37)])#
clust <- hclust(dij, method = "average")#
ord <- order(cutree(clust, k = 4))#
coph <- cophenetic(clust)#
layout(matrix(1:4, ncol = 2))#
image(as.matrix(dij)[ord, ord], main = "Original distances")#
image(as.matrix(coph)[ord, ord], main = "Cophenetic distances")#
image((as.matrix(coph) - as.matrix(dij))[ord, ord], #
      main = "Cophenetic - Original")#
plot(coph ~ dij, ylab = "Cophenetic distances", xlab = "Original distances",#
     main = "Shepard Plot")#
abline(0,1, col = "red")#
box()#
layout(1)
ls()
head(Alz_TopModel_REV)
head(ForSIMI_w_demogs)
head(ForSIMI)
ls()
head(ForSIMI_w)
ForS.numeric<-apply(ForSIMI_w[,-1], c(1,2), function(x) as.numeric(as.character(x)))
warnings()
head(ForS.numeric)
head(ForSIMI_w[,-1])
1#
factor2numeric()
factor2numeric()
factor2numeric<-function(x) as.numeric(as.character(x))
factor2numeric
head(apply(ForSIMI_w[,-1], 2, factor2numeric))
head(apply(ForSIMI_w[,-1], 1, factor2numeric))
head(.data)
head(spread(ForSIMI, Region, k))
library()
spread
??spread
library(tidyr)
head(spread(ForSIMI, Region, k))
head(spread(ForSIMI, Region, k_hilo.1))
head(spread(ForSIMI, Region, k_hilo.1))
ls()
dim(ForSIMI_w); head(ForSIMI_w)
as.numeric(as.character(ForSIMI_w[,-1]))
# HCLUST#
# shrink DF#
ForSIMI.NUM<-subset(Alz_TopModel_23, variable=="P")#
ForSIMI.NUM<-ForSIMI.NUM[,c(5,13,2)]#
head(ForSIMI.NUM)#
ForSIMI.NUM_w<- reshape(ForSIMI.NUM, v.names=c("k"), idvar="PIB",  timevar= "Region", direction="wide")
head(ForSIMI.NUM_w)
apply(ForSIMI.NUM_w[,-1], 2,  factor2numeric)
ForSIMI.NUM_wapply(ForSIMI.NUM_w[,-1], 2,  factor2numeric)
.data<-apply(ForSIMI.NUM_w[,-1], 2,  factor2numeric)
dij <- dist(.data)#
clust <- hclust(dij, method = "average")#
ord <- order(cutree(clust, k = 4))#
coph <- cophenetic(clust)#
#
layout(matrix(1:4, ncol = 2))#
image(as.matrix(dij)[ord, ord], main = "Original distances")#
image(as.matrix(coph)[ord, ord], main = "Cophenetic distances")#
image((as.matrix(coph) - as.matrix(dij))[ord, ord], #
      main = "Cophenetic - Original")#
plot(coph ~ dij, ylab = "Cophenetic distances", xlab = "Original distances",#
     main = "Shepard Plot")#
abline(0,1, col = "red")#
box()#
layout(1)
ord <- order(cutree(clust, k = 10))
coph <- cophenetic(clust)
layout(matrix(1:4, ncol = 2))
image(as.matrix(dij)[ord, ord], main = "Original distances")
image(as.matrix(coph)[ord, ord], main = "Cophenetic distances")
image((as.matrix(coph) - as.matrix(dij))[ord, ord],
main = "Cophenetic - Original")
main = "Shepard Plot")
plot(coph ~ dij, ylab = "Cophenetic distances", xlab = "Original distances",
abline(0,1, col = "red")
layout(1)
box()
kmeans
?kmeans
d_clust <- Mclust(as.matrix(dij), G=1:20)
library(mclust)
# Run the function to see how many clusters
# it finds to be optimal, set it to search for
# at least 1 model and up 20.
d_clust <- Mclust(as.matrix(dij), G=1:20)
m.best <- dim(d_clust$z)[2]
cat("model-based optimal number of clusters:", m.best, "\n")
# 4 clusters
plot(d_clust)
library(mclust)#
# Run the function to see how many clusters#
# it finds to be optimal, set it to search for#
# at least 1 model and up 20.#
d_clust <- Mclust(as.matrix(.data), G=1:20)#
m.best <- dim(d_clust$z)[2]#
cat("model-based optimal number of clusters:", m.best, "\n")#
# 4 clusters#
plot(d_clust)
3
3#
4
plot(d_clust)
mydata <- .data
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
ylab="Within groups sum of squares")
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
mydata <-BigY[,c(4:35,37)]
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
par(mfrow=c(1,2))
mydata <- .data
mydata <-BigY[,c(4:35,37)]
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:20) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:20, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
mydata <- .data
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))#
  for (i in 2:20) wss[i] <- sum(kmeans(mydata,#
                                       centers=i)$withinss)#
plot(1:20, wss, type="b", xlab="Number of Clusters",#
     ylab="Within groups sum of squares")
ls()
load('~/Google Drive/Work/CSIRO_P1/Code/all.pc.zmixMVN.RDATA')
ls()
all.pc.zmixMVN.pp[[1]]
all.pc.zmixMVN.pp[[2]]
all.pc.zmixMVN.pp[[3]]
all.pc.zmixMVN.pp[[1]]
all.pc.zmixMVN.pp[[3]]
all.pc.zmixMVN.pp[[1]]
load('~/Google Drive/Work/CSIRO_P1/Code/all.pc.zmixMVN.RDATA')
all.pc.zmixMVN.pp[[3]]
data.frame(demogs,BigY[,c(4:35,37)], PC_k3=all.pc.zmixMVN.pp[[3]])
ALLres_PC_zmixMVN<-data.frame(demogs,BigY[,c(4:35,37)], PC_k3=all.pc.zmixMVN.pp[[3]])
ls()
